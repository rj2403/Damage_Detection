{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T07:33:23.031219Z",
     "start_time": "2021-06-17T07:33:17.750554Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "# keras imports\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "\n",
    "# other imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T07:33:24.594185Z",
     "start_time": "2021-06-17T07:33:24.586379Z"
    }
   },
   "outputs": [],
   "source": [
    "config={\n",
    "  \"model\"           : \"vgg16\",\n",
    "  \"weights\"         : \"imagenet\",\n",
    "  \"include_top\"     : False,\n",
    "\n",
    "  \"train_path\"      : [\"train_p/Bonnet\",\"train_p/Rear\",\"train_p/Left\",\"train_p/Right\"],\n",
    "  \"test_path\"       : \"test_p\",\n",
    "  \"features_path\"   : \"car_parts_check/features.h5\",\n",
    "  \"labels_path\"     : \"car_parts_check/labels.h5\",\n",
    "  \"results\"         : \"car_parts_check/results.txt\",\n",
    "  \"classifier_path\" : \"car_parts_check/classifier.pickle\",\n",
    "  \"model_path\"      : \"car_parts_check/model\",\n",
    "\n",
    "  \"test_size\"       : 0.20,\n",
    "  \"seed\"            : 9,\n",
    "  \"num_classes\"     : 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T07:33:24.998302Z",
     "start_time": "2021-06-17T07:33:24.985741Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name  = config[\"model\"]\n",
    "weights     = config[\"weights\"]\n",
    "include_top   = config[\"include_top\"]\n",
    "\n",
    "train_path    = config[\"train_path\"]\n",
    "\n",
    "test_path    = config[\"test_path\"]\n",
    "features_path   = config[\"features_path\"]\n",
    "labels_path   = config[\"labels_path\"]\n",
    "test_size     = config[\"test_size\"]\n",
    "results     = config[\"results\"]\n",
    "model_path    = config[\"model_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_p/Bonnet', 'train_p/Rear', 'train_p/Left', 'train_p/Right']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T07:33:28.237852Z",
     "start_time": "2021-06-17T07:33:25.320582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded base model and model...\n"
     ]
    }
   ],
   "source": [
    "if model_name == \"vgg16\":\n",
    "    base_model = VGG16(weights=weights)\n",
    "    model = Model(base_model.input,base_model.get_layer('fc1').output)\n",
    "    image_size = (224, 224)\n",
    "else:\n",
    "    base_model = None\n",
    "\n",
    "print (\"Successfully loaded base model and model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T07:34:03.168597Z",
     "start_time": "2021-06-17T07:33:28.354662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding labels...\n",
      "Processed - 1\n",
      "Completed label - bonnet (1).jpg\n",
      "Processed - 2\n",
      "Completed label - bonnet (10).jpg\n",
      "Processed - 3\n",
      "Completed label - bonnet (11).jpg\n",
      "Processed - 4\n",
      "Completed label - bonnet (12).jpg\n",
      "Processed - 5\n",
      "Completed label - bonnet (13).jpg\n",
      "Processed - 6\n",
      "Completed label - bonnet (14).jpg\n",
      "Processed - 7\n",
      "Completed label - bonnet (15).jpg\n",
      "Processed - 8\n",
      "Completed label - bonnet (16).jpg\n",
      "Processed - 9\n",
      "Completed label - bonnet (17).jpg\n",
      "Processed - 10\n",
      "Completed label - bonnet (18).jpg\n",
      "Processed - 11\n",
      "Completed label - bonnet (19).jpg\n",
      "Processed - 12\n",
      "Completed label - bonnet (2).jpg\n",
      "Processed - 13\n",
      "Completed label - bonnet (20).jpg\n",
      "Processed - 14\n",
      "Completed label - bonnet (21).jpg\n",
      "Processed - 15\n",
      "Completed label - bonnet (22).jpg\n",
      "Processed - 16\n",
      "Completed label - bonnet (3).jpg\n",
      "Processed - 17\n",
      "Completed label - bonnet (4).jpg\n",
      "Processed - 18\n",
      "Completed label - bonnet (5).jpg\n",
      "Processed - 19\n",
      "Completed label - bonnet (6).jpg\n",
      "Processed - 20\n",
      "Completed label - bonnet (7).jpg\n",
      "Processed - 21\n",
      "Completed label - bonnet (8).jpg\n",
      "Processed - 22\n",
      "Completed label - bonnet (9).jpg\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Training labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Training labels shape: (22,)\n",
      "Encoding labels...\n",
      "Processed - 1\n",
      "Completed label - Rear (1).jpg\n",
      "Processed - 2\n",
      "Completed label - Rear (10).jpg\n",
      "Processed - 3\n",
      "Completed label - Rear (11).jpg\n",
      "Processed - 4\n",
      "Completed label - Rear (12).jpg\n",
      "Processed - 5\n",
      "Completed label - Rear (13).jpg\n",
      "Processed - 6\n",
      "Completed label - Rear (14).jpg\n",
      "Processed - 7\n",
      "Completed label - Rear (15).jpg\n",
      "Processed - 8\n",
      "Completed label - Rear (16).jpg\n",
      "Processed - 9\n",
      "Completed label - Rear (17).jpg\n",
      "Processed - 10\n",
      "Completed label - Rear (18).jpg\n",
      "Processed - 11\n",
      "Completed label - Rear (19).jpg\n",
      "Processed - 12\n",
      "Completed label - Rear (2).jpg\n",
      "Processed - 13\n",
      "Completed label - Rear (20).jpg\n",
      "Processed - 14\n",
      "Completed label - Rear (21).jpg\n",
      "Processed - 15\n",
      "Completed label - Rear (3).jpg\n",
      "Processed - 16\n",
      "Completed label - Rear (4).jpg\n",
      "Processed - 17\n",
      "Completed label - Rear (5).jpg\n",
      "Processed - 18\n",
      "Completed label - Rear (6).jpg\n",
      "Processed - 19\n",
      "Completed label - Rear (7).jpg\n",
      "Processed - 20\n",
      "Completed label - Rear (8).jpg\n",
      "Processed - 21\n",
      "Completed label - Rear (9).jpg\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Training labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Training labels shape: (21,)\n",
      "Encoding labels...\n",
      "Processed - 1\n",
      "Completed label - left (1).jpg\n",
      "Processed - 2\n",
      "Completed label - left (2).jpg\n",
      "Processed - 3\n",
      "Completed label - left (3).jpg\n",
      "Processed - 4\n",
      "Completed label - left (4).jpg\n",
      "Processed - 5\n",
      "Completed label - left (5).jpg\n",
      "Processed - 6\n",
      "Completed label - left (6).jpg\n",
      "Processed - 7\n",
      "Completed label - left (7).jpg\n",
      "Processed - 8\n",
      "Completed label - left (8).jpg\n",
      "Processed - 9\n",
      "Completed label - left (9).jpg\n",
      "[3 3 3 3 3 3 3 3 3]\n",
      "Training labels: [3 3 3 3 3 3 3 3 3]\n",
      "Training labels shape: (9,)\n",
      "Encoding labels...\n",
      "Processed - 1\n",
      "Completed label - Right (1).jpg\n",
      "Processed - 2\n",
      "Completed label - Right (10).jpg\n",
      "Processed - 3\n",
      "Completed label - Right (11).jpg\n",
      "Processed - 4\n",
      "Completed label - Right (12).jpg\n",
      "Processed - 5\n",
      "Completed label - Right (13).jpg\n",
      "Processed - 6\n",
      "Completed label - Right (14).jpg\n",
      "Processed - 7\n",
      "Completed label - Right (15).jpg\n",
      "Processed - 8\n",
      "Completed label - Right (16).jpg\n",
      "Processed - 9\n",
      "Completed label - Right (17).jpg\n",
      "Processed - 10\n",
      "Completed label - Right (18).jpg\n",
      "Processed - 11\n",
      "Completed label - Right (2).jpg\n",
      "Processed - 12\n",
      "Completed label - Right (3).jpg\n",
      "Processed - 13\n",
      "Completed label - Right (4).jpg\n",
      "Processed - 14\n",
      "Completed label - Right (5).jpg\n",
      "Processed - 15\n",
      "Completed label - Right (6).jpg\n",
      "Processed - 16\n",
      "Completed label - Right (7).jpg\n",
      "Processed - 17\n",
      "Completed label - Right (8).jpg\n",
      "Processed - 18\n",
      "Completed label - Right (9).jpg\n",
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "Training labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "Training labels shape: (18,)\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "labels = []\n",
    "le_labels   = []\n",
    "j = 1\n",
    "for k in train_path:\n",
    "    train_labels = os.listdir(k)\n",
    "    # encode the labels\n",
    "    print (\"Encoding labels...\")\n",
    "    le = LabelEncoder()\n",
    "    le.fit([tl for tl in train_labels])\n",
    "\n",
    "    # loop over all the labels in the folder\n",
    "    count = 1\n",
    "    for i, label in enumerate(train_labels):\n",
    "        cur_path = k + \"/\" + label\n",
    "        for image_path in glob.glob(cur_path):\n",
    "            img = image.load_img(image_path, target_size=image_size)\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            feature = model.predict(x)\n",
    "            flat = feature.flatten()\n",
    "            features.append(flat)\n",
    "            labels.append(label)\n",
    "            print (\"Processed - \" + str(count))\n",
    "            count += 1\n",
    "        print (\"Completed label - \" + label)\n",
    "    # encode the labels using LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    #le_labels = le.fit_transform(labels)\n",
    "    l = [j for i in range(1,count)]\n",
    "    j += 1\n",
    "    le_label = np.array(l)\n",
    "    print(le_label)\n",
    "    # get the shape of training labels\n",
    "    print (\"Training labels: {}\".format(le_label))\n",
    "    print (\"Training labels shape: {}\".format(le_label.shape))\n",
    "    le_labels.append(le_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_labels = np.concatenate(le_labels).ravel()\n",
    "le_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T07:34:33.617568Z",
     "start_time": "2021-06-17T07:34:33.612981Z"
    }
   },
   "outputs": [],
   "source": [
    "#Bonnet - 1\n",
    "#Rear - 2\n",
    "#Left - 3\n",
    "#Right - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T07:34:35.849574Z",
     "start_time": "2021-06-17T07:34:34.183996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and weights to disk..\n",
      "Features and labels saved..\n",
      "End time - 2021-06-18 15:40\n"
     ]
    }
   ],
   "source": [
    "h5f_data = h5py.File(features_path, 'w')\n",
    "h5f_data.create_dataset('dataset_1', data=np.array(features))\n",
    "\n",
    "h5f_label = h5py.File(labels_path, 'w')\n",
    "h5f_label.create_dataset('dataset_1', data=np.array(le_labels))\n",
    "\n",
    "h5f_data.close()\n",
    "h5f_label.close()\n",
    "\n",
    "# save model and weights\n",
    "model_json = model.to_json()\n",
    "with open(model_path + str(test_size) + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# save weights\n",
    "model.save_weights(model_path + str(test_size) + \".h5\")\n",
    "print(\"Saved model and weights to disk..\")\n",
    "\n",
    "print (\"Features and labels saved..\")\n",
    "\n",
    "# end time\n",
    "end = time.time()\n",
    "print (\"End time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T07:38:40.836951Z",
     "start_time": "2021-06-17T07:38:40.827658Z"
    }
   },
   "outputs": [],
   "source": [
    "config={\n",
    "  \"model\"           : \"vgg16\",\n",
    "  \"weights\"         : \"imagenet\",\n",
    "  \"features_path\"   : \"car_parts_check/features.h5\",\n",
    "  \"labels_path\"     : \"car_parts_check/labels.h5\",\n",
    "  \"classifier_path\" : \"car_parts_check/classifier.pickle\",\n",
    "  \"model_path\"      : \"cdd/car_parts_check/model\",\n",
    "\n",
    "  \"test_size\"       : 0.10,\n",
    "  \"seed\"            : 9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T07:38:41.302519Z",
     "start_time": "2021-06-17T07:38:41.287721Z"
    }
   },
   "outputs": [],
   "source": [
    "test_size  = config[\"test_size\"]\n",
    "seed = config[\"seed\"]\n",
    "features_path = config[\"features_path\"]\n",
    "labels_path = config[\"labels_path\"]\n",
    "classifier_path = config[\"classifier_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T07:38:41.766511Z",
     "start_time": "2021-06-17T07:38:41.746321Z"
    }
   },
   "outputs": [],
   "source": [
    "# import features and labels\n",
    "h5f_data  = h5py.File(features_path, 'r')\n",
    "h5f_label = h5py.File(labels_path, 'r')\n",
    "\n",
    "features_string = h5f_data['dataset_1']\n",
    "labels_string   = h5f_label['dataset_1']\n",
    "\n",
    "features = np.array(features_string)\n",
    "labels   = np.array(labels_string)\n",
    "\n",
    "h5f_data.close()\n",
    "h5f_label.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T07:38:42.223299Z",
     "start_time": "2021-06-17T07:38:42.201438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 4096)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T07:38:42.809424Z",
     "start_time": "2021-06-17T07:38:42.784312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 4096)\n",
      "(70,)\n",
      "[INFO] training started...\n",
      "[INFO] splitted train and test data...\n",
      "[INFO] train data  : (63, 4096)\n",
      "[INFO] test data   : (7, 4096)\n",
      "[INFO] train labels: (63,)\n",
      "[INFO] test labels : (7,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# verify the shape of features and labels\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "print (\"[INFO] training started...\")\n",
    "# split the training and testing data\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(features),\n",
    "                                                                  np.array(labels),\n",
    "                                                                  test_size=test_size,\n",
    "                                                                  random_state=seed)\n",
    "\n",
    "print (\"[INFO] splitted train and test data...\")\n",
    "print (\"[INFO] train data  : {}\".format(trainData.shape))\n",
    "print (\"[INFO] test data   : {}\".format(testData.shape))\n",
    "print (\"[INFO] train labels: {}\".format(trainLabels.shape))\n",
    "print (\"[INFO] test labels : {}\".format(testLabels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:07:49.468522Z",
     "start_time": "2021-06-17T08:07:49.351740Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:08:05.490114Z",
     "start_time": "2021-06-17T08:08:05.239562Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jroha\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:40:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier()\n",
    "clf.fit(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:08:07.320521Z",
     "start_time": "2021-06-17T08:08:07.286535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 2 1 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(testData)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:08:09.446666Z",
     "start_time": "2021-06-17T08:08:09.384190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving model...\n",
      "[INFO] Loading the classifier...\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "print (\"[INFO] saving model...\")\n",
    "pickle.dump(clf, open(classifier_path, 'wb'))\n",
    "\n",
    "import pickle\n",
    "print (\"[INFO] Loading the classifier...\")\n",
    "classifier = pickle.load(open(config[\"classifier_path\"], 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:18:21.785545Z",
     "start_time": "2021-06-17T08:18:15.842891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed - 1\n",
      "Completed label - test (1).jpg\n",
      "Processed - 1\n",
      "Completed label - test (2).jpg\n",
      "Processed - 1\n",
      "Completed label - test (3).jpg\n",
      "Processed - 1\n",
      "Completed label - test (4).jpg\n",
      "Processed - 1\n",
      "Completed label - test (5).jpg\n",
      "Processed - 1\n",
      "Completed label - test (6).jpg\n",
      "Processed - 1\n",
      "Completed label - test (7).jpg\n",
      "Processed - 1\n",
      "Completed label - test (8).jpg\n"
     ]
    }
   ],
   "source": [
    "test_labels = os.listdir(test_path)\n",
    "# variables to hold features and labels\n",
    "features_new = []\n",
    "\n",
    "# loop over all the labels in the folder\n",
    "count = 1\n",
    "for i, label in enumerate(test_labels):\n",
    "    cur_path = test_path + \"/\" + label\n",
    "    count = 1\n",
    "    for image_path in glob.glob(cur_path):\n",
    "        img = image.load_img(image_path, target_size=image_size)\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        feature = model.predict(x)\n",
    "        flat = feature.flatten()\n",
    "        features_new.append(flat)\n",
    "        print (\"Processed - \" + str(count))\n",
    "        count += 1\n",
    "    print (\"Completed label - \" + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:18:36.350257Z",
     "start_time": "2021-06-17T08:18:36.312078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 4, 1, 1, 3, 4, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict(np.array(features_new))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T07:38:51.803574Z",
     "start_time": "2021-06-17T07:38:51.795319Z"
    }
   },
   "outputs": [],
   "source": [
    "#Bonnet - 1\n",
    "#Rear - 2\n",
    "#Left - 3\n",
    "#Right - 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
